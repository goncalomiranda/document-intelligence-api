version: "3.8"

services:
  document-intelligence-api:
    # Use pre-built image from Docker Hub
    image: ${DOCKERHUB_USERNAME}/document-intelligence-api:latest
    # Uncomment below to build locally instead
    # build:
    #   context: .
    #   dockerfile: Dockerfile
    container_name: document-intelligence-api
    restart: unless-stopped
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - PORT=3001
      # API Keys
      - API_KEY_CARDOC=${API_KEY_CARDOC}
      - API_KEY_MORTGAGE=${API_KEY_MORTGAGE}
      # Ollama Configuration - Point to host machine or another container
      - OLLAMA_API_URL=${OLLAMA_API_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2:3b}
      - OLLAMA_TIMEOUT=${OLLAMA_TIMEOUT:-60000}
      - OLLAMA_DEFAULT_PROMPT=${OLLAMA_DEFAULT_PROMPT:-Analyze this document and provide a concise summary with key information.}
      # Rate Limiting
      - RATE_LIMIT_WINDOW_MS=${RATE_LIMIT_WINDOW_MS:-900000}
      - RATE_LIMIT_MAX_REQUESTS=${RATE_LIMIT_MAX_REQUESTS:-100}
      # File Upload
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-3145728}
      - ALLOWED_MIME_TYPES=${ALLOWED_MIME_TYPES:-application/pdf,image/png,image/jpeg}
      # Debug
      - DEBUG_SAVE_FILES=${DEBUG_SAVE_FILES:-true}
      - DEBUG_DIR=${DEBUG_DIR:-./debug}
      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-info}
    volumes:
      - ./debug:/app/debug
    # Use host network mode to access Ollama on host machine (alternative to host.docker.internal)
    # network_mode: host
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost:3001/api/v1/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
